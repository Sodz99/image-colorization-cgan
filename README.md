# ğŸ¨ Image Colorization with Conditional Wasserstein GANs

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.9%2B-red.svg)](https://pytorch.org/)
[![PyTorch Lightning](https://img.shields.io/badge/PyTorch%20Lightning-1.5%2B-purple.svg)](https://www.pytorchlightning.ai/)

> **A deep learning approach to automatic image colorization using Conditional Wasserstein GANs with advanced regularization techniques.**


## ğŸŒŸ Project Overview

This project implements a **Conditional Wasserstein GAN (CWGAN)** architecture for automatic grayscale-to-color image translation. The system leverages advanced deep learning techniques including gradient penalty, R1 regularization, and a ResU-Net generator architecture to produce high-quality, realistic colorizations.

### ğŸ¯ Key Features

- **GAN Architecture**: Conditional Wasserstein GAN with gradient penalty and R1 regularization
- **Custom ResU-Net Generator**: U-Net with residual connections for enhanced feature preservation
- **PatchGAN Discriminator**: Efficient adversarial training with instance normalization
- **LAB Color Space**: Perceptually uniform color representation for optimal results
- **Evaluation**: Inception Score and FID metrics for quantitative assessment


## ğŸ—ï¸ Architecture

### Generator: ResU-Net
```
ğŸ“¦ ResU-Net Generator (8.2M parameters)
â”œâ”€â”€ Encoder Path
â”‚   â”œâ”€â”€ ResBlock(1â†’64) + Dropout
â”‚   â”œâ”€â”€ DownSample(64â†’128) + Dropout  
â”‚   â”œâ”€â”€ DownSample(128â†’256) + Dropout
â”‚   â””â”€â”€ Bridge(256â†’512) + Dropout
â””â”€â”€ Decoder Path
    â”œâ”€â”€ UpSample(512â†’256) + Skip Connection
    â”œâ”€â”€ UpSample(256â†’128) + Skip Connection
    â”œâ”€â”€ UpSample(128â†’64) + Skip Connection
    â””â”€â”€ Output Conv(64â†’2)
```

### Discriminator: PatchGAN Critic
```
ğŸ” PatchGAN Critic (2.7M parameters)
â”œâ”€â”€ Conv2d(3â†’64) + LeakyReLU
â”œâ”€â”€ Conv2d(64â†’128) + InstanceNorm + LeakyReLU
â”œâ”€â”€ Conv2d(128â†’256) + InstanceNorm + LeakyReLU
â”œâ”€â”€ Conv2d(256â†’512) + InstanceNorm + LeakyReLU
â”œâ”€â”€ AdaptiveAvgPool2d(1)
â””â”€â”€ Linear(512â†’1)
```

## ğŸ“Š Results & Performance

### Quantitative Metrics
| Metric | Real Images | Generated Images |
|--------|-------------|------------------|
| **Inception Score** | 4.34 Â± 1.80 | 4.31 Â± 1.84 |
| **FID Score** | - | **13.11** |

### Training Configuration
- **Optimizer**: Adam (Î²â‚=0.5, Î²â‚‚=0.9)
- **Learning Rate**: 2e-4
- **Loss Function**: L1 Reconstruction + WGAN-GP + R1 Regularization
- **Batch Size**: 1 (GPU memory optimized)
- **Epochs**: 150
- **Regularization**: Î»_GP=10, Î»_R1=10, Î»_recon=100

## ğŸ“Š Dataset

The model is trained on the **Image Colorization Dataset**:

ğŸ”— **Dataset Source**: [Kaggle - Image Colorization Dataset](https://www.kaggle.com/datasets/shravankumar9892/image-colorization)

- **Training samples**: 5,000 images (224Ã—224 resolution)
- **Format**: Separate `.npy` files for L and AB channels
- **Preprocessing**: Images converted to LAB color space with normalization

## ğŸš€ Quick Start

### Prerequisites
```bash
pip install torch torchvision pytorch-lightning
pip install opencv-python scikit-image matplotlib
pip install numpy pandas tqdm torchsummary
```

### Usage
1. **Data Preparation**: Download dataset and convert images to LAB color space
```python
# Download from Kaggle: https://www.kaggle.com/datasets/shravankumar9892/image-colorization
# L channel (grayscale) as input - shape: (224,224,1)
# AB channels (color information) as ground truth - shape: (224,224,2)
```

2. **Training**:
```python
cwgan = CWGAN(in_channels=1, out_channels=2, learning_rate=2e-4)
trainer = pl.Trainer(max_epochs=150, accelerator="gpu")
trainer.fit(cwgan, train_loader)
```

3. **Inference**:
```python
# Generate colorized image from grayscale input
colorized = cwgan.generator(grayscale_image)
```

## ğŸ”¬ Technical Highlights

### Advanced Training Techniques
- **Wasserstein Loss with Gradient Penalty**: Stable GAN training with improved convergence
- **R1 Regularization**: Enhanced discriminator stability and reduced mode collapse
- **LAB Color Space**: Perceptually uniform representation for better color fidelity
- **Residual Connections**: Gradient flow optimization in deep U-Net architecture

### Model Innovations
- **Skip Connections**: Preserve fine-grained details during upsampling
- **Instance Normalization**: Improved discriminator performance
- **Adaptive Pooling**: Resolution-independent feature extraction
- **Progressive Training**: Stable adversarial learning dynamics

## ğŸ“ Project Structure

```
Image Colorization using Conditional Wasserstein GANs/
â”œâ”€â”€ image-colorization-cwgan.ipynb    # Main implementation
â”œâ”€â”€ Project_Report.pdf                # Technical documentation
â”œâ”€â”€ Image Colorization using Conditional Wasserstein GANs.pptx  # Results presentation
â””â”€â”€ README.md                         # Project documentation
```

## ğŸ› ï¸ Implementation Details

### Dataset Processing
- **Input**: Grayscale images (L channel) - 224Ã—224Ã—1
- **Output**: Color channels (AB channels) - 224Ã—224Ã—2
- **Preprocessing**: LAB color space conversion with normalization
- **Data Augmentation**: Standard computer vision transforms

### Loss Functions
```python
# Generator Loss
L_gen = L1_loss(fake_ab, real_ab) + Î»_adv * WGAN_loss

# Discriminator Loss  
L_disc = WGAN_loss + Î»_gp * gradient_penalty + Î»_r1 * r1_regularization
```

## ğŸ“ˆ Performance Analysis

The model achieves competitive results with:
- **High Visual Fidelity**: Realistic color distributions matching natural images
- **Stable Training**: Wasserstein distance provides stable gradient signals  
- **Efficient Architecture**: Optimized parameter count vs. performance ratio
- **Quantitative Validation**: Professional evaluation metrics (IS, FID)



## ğŸ“ Future Enhancements

- [ ] Multi-scale discriminator for better detail preservation
- [ ] Perceptual loss integration for enhanced realism
- [ ] Real-time inference optimization
- [ ] Web interface for interactive colorization
- [ ] Dataset expansion with diverse image categories

## ğŸ“š References

[1] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, "Generative adversarial nets," in Proc. Adv. Neural Inf. Process. Syst. (NIPS), 2014, pp. 2672â€“2680.

[2] P. Isola, J.-Y. Zhu, T. Zhou, and A. A. Efros, "Image-to-image translation with conditional adversarial networks," in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), 2017, pp. 1125â€“1134.

[3] M. Arjovsky, S. Chintala, and L. Bottou, "Wasserstein generative adversarial networks," in Proc. Int. Conf. Mach. Learn. (ICML), 2017, pp. 214â€“223.

[4] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. C. Courville, "Improved training of Wasserstein GANs," in Proc. Adv. Neural Inf. Process. Syst. (NIPS), 2017, pp. 5767â€“5777.

[5] O. Ronneberger, P. Fischer, and T. Brox, "U-net: Convolutional networks for biomedical image segmentation," in Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent. (MICCAI), 2015, pp. 234â€“241.

[6] K. He, X. Zhang, S. Ren, and J. Sun, "Deep residual learning for image recognition," in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), 2016, pp. 770â€“778.

[7] R. Zhang, P. Isola, and A. A. Efros, "Colorful image colorization," in Proc. Eur. Conf. Comput. Vis. (ECCV), 2016, pp. 649â€“666.

[8] T. Salimans, I. Goodfellow, W. Zaremba, V. Cheung, A. Radford, and X. Chen, "Improved techniques for training GANs," in Proc. Adv. Neural Inf. Process. Syst. (NIPS), 2016, pp. 2234â€“2242.

## ğŸ‘¤ Author

**Sohan Arun**  
Masterâ€™s Student, Computer Science  
Blekinge Institute of Technology, Sweden  
ğŸ“§ [Sohanoffice46@gmail.com](mailto:Sohanoffice46@gmail.com)

For detailed technical analysis, experimental setup, and theoretical background, please refer to the complete research report: Project_Report.pdf
